# Default Spring Boot properties
spring.application.name=ai_research

# Agent Card Configuration (can be overridden by environment variables)
agent.card.id=${AGENT_CARD_ID:-ai-research-agent-2025}
agent.card.name=${AGENT_CARD_NAME:-Research Assistant Agent}
agent.card.description=${AGENT_CARD_DESCRIPTION:-An AI agent that helps with research tasks and information retrieval.}
agent.card.url=${AGENT_CARD_URL:-http://localhost:8080/research-agent/api}
agent.card.provider.organization=${AGENT_CARD_PROVIDER_ORGANIZATION:-AI Research Lab}
agent.card.provider.url=${AGENT_CARD_PROVIDER_URL:-https://example.com}
agent.card.contact_email=${AGENT_CARD_CONTACT_EMAIL:-contact@example.com}

# H2 Database Configuration (can be overridden by environment variables)
spring.datasource.url=${SPRING_DATASOURCE_URL:jdbc:h2:./data/airesearch}
spring.datasource.driverClassName=org.h2.Driver
spring.datasource.username=${SPRING_DATASOURCE_USERNAME:sa}
spring.datasource.password=${SPRING_DATASOURCE_PASSWORD:password}
spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
spring.jpa.hibernate.ddl-auto=${SPRING_JPA_HIBERNATE_DDL_AUTO:update}
spring.h2.console.enabled=${SPRING_H2_CONSOLE_ENABLED:true}
spring.h2.console.path=${SPRING_H2_CONSOLE_PATH:/h2-console}

# External MCP Servers
agent.integrations.mcp-servers[0].name=${MCP_SERVER_0_NAME:-ExternalMCP1}
agent.integrations.mcp-servers[0].url=${MCP_SERVER_0_URL:http://external-mcp-server1.com/api}

agent.integrations.mcp-servers[1].name=${MCP_SERVER_1_NAME:-AnotherMCP}
agent.integrations.mcp-servers[1].url=${MCP_SERVER_1_URL:http://another-mcp.com/mcp}

# External A2A Agents (Peers)
agent.integrations.a2a-peers[0].name=${A2A_PEER_0_NAME:-PeerAlpha}
agent.integrations.a2a-peers[0].url=${A2A_PEER_0_URL:http://localhost:8081}

agent.integrations.a2a-peers[1].name=${A2A_PEER_1_NAME:-ServiceAgentBeta}
agent.integrations.a2a-peers[1].url=${A2A_PEER_1_URL:http://localhost:8082}

# OpenAI API Configuration (MUST be overridden by environment variables for security)
openai.api.baseurl=${OPENAI_API_BASEURL:http://192.168.12.10:1234/v1}
openai.api.key=${OPENAI_API_KEY:YOUR_OPENAI_API_KEY_HERE}
openai.api.model=${OPENAI_API_MODEL:gpt-4o}

# LLM Configurations - defines which models are available and their capabilities
# This allows the backend to understand which models support multimodal inputs
# The frontend can fetch this information to provide appropriate UI and warnings

# Google Gemma (text-only model)
llm.configurations[0].id=${LLM_CONFIG_0_ID:gemma-7b}
llm.configurations[0].name=${LLM_CONFIG_0_NAME:Google Gemma 7B}
llm.configurations[0].supportsText=${LLM_CONFIG_0_SUPPORTS_TEXT:true}
llm.configurations[0].supportsImage=${LLM_CONFIG_0_SUPPORTS_IMAGE:false}
llm.configurations[0].supportsPdf=${LLM_CONFIG_0_SUPPORTS_PDF:false}
llm.configurations[0].notes=${LLM_CONFIG_0_NOTES:Text-only model, no multimodal capabilities}

# Claude 3 Opus (vision-enabled model)
llm.configurations[1].id=${LLM_CONFIG_1_ID:claude-3-opus}
llm.configurations[1].name=${LLM_CONFIG_1_NAME:Anthropic Claude 3 Opus}
llm.configurations[1].supportsText=${LLM_CONFIG_1_SUPPORTS_TEXT:true}
llm.configurations[1].supportsImage=${LLM_CONFIG_1_SUPPORTS_IMAGE:true}
llm.configurations[1].supportsPdf=${LLM_CONFIG_1_SUPPORTS_PDF:false}
llm.configurations[1].notes=${LLM_CONFIG_1_NOTES:Supports image analysis up to 10MB per image}

# GPT-4o (vision-enabled model with PDF support)
llm.configurations[2].id=${LLM_CONFIG_2_ID:gpt-4o}
llm.configurations[2].name=${LLM_CONFIG_2_NAME:OpenAI GPT-4o}
llm.configurations[2].supportsText=${LLM_CONFIG_2_SUPPORTS_TEXT:true}
llm.configurations[2].supportsImage=${LLM_CONFIG_2_SUPPORTS_IMAGE:true}
llm.configurations[2].supportsPdf=${LLM_CONFIG_2_SUPPORTS_PDF:true}
llm.configurations[2].notes=${LLM_CONFIG_2_NOTES:Supports image analysis and PDF processing via backend extraction}
